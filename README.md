ğŸ“Š **Trend Analyzer â€“ AI-Powered Multi-Source Trend & Sentiment Explorer**

Trend Analyzer is an AI-driven system that collects real-time data from Reddit, News, and Twitter, analyzes sentiment, generates short AI summaries for each post/article, and produces a final overall trend summary using an LLM.

It also stores all searches in MongoDB and lets users retrieve history, word clouds, and summaries for any keyword.

ğŸš€ **Features**
ğŸ” Multi-Source Data Collection

For any keyword, the system fetches:

ğŸ”¸ Reddit comments

ğŸ”¸ News articles

ğŸ”¸ Tweets

ğŸ§  **AI-Based Processing**

Every post/article is passed through:

âœ” Sentiment analysis

âœ” Short AI-generated summary (per post)

âœ” Combined overall AI-generated summary (all sources)

ğŸ“¦ **Backend Services**

The FastAPI backend provides:

/trend/{keyword} â†’ Fetch fresh data + store in DB

/trend_summary/{keyword} â†’ Fetch or generate overall summary

/trend_history/{keyword} â†’ Get past searches

ğŸ—ƒ **MongoDB Storage**

Every trend fetch is stored with:

{
  keyword,
  results: [
    { source, text, sentiment, summary, ... }
  ],
  created_at
}

ğŸ¯ **Summaries You Get**

1. Per-post summary â†’ 50-word micro-summary
2. Full combined summary â†’ LLM-generated theme-level summary

ğŸ› ï¸ **Tech Stack**
**Backend**

Python

FastAPI

NLTK / VADER sentiment

LLM models for summary (Gemini/OpenRouter/OpenAI)

Requests

PyMongo

**Database**

MongoDB (cloud/local)

**Frontend**

HTML, CSS, JS

ğŸ”¥ **API Endpoints**
1ï¸âƒ£ Fetch Fresh Trend Data
GET /trend/{keyword}

This endpoint:

Fetches Reddit comments

Fetches News articles

Fetches Tweets

Performs sentiment analysis

Generates per-post summaries

Saves everything in MongoDB

Sample Response
{
  "keyword": "AI",
  "results": [
    {
      "source": "reddit",
      "text": "...",
      "sentiment": "positive",
      "summary": "Short AI summary..."
    },
    {
      "source": "news",
      "title": "AI is transforming business...",
      "text": "...",
      "sentiment": "neutral",
      "summary": "Short AI summary..."
    }
  ]
}

2ï¸âƒ£ Get Historical Trend Data
GET /trend_history/{keyword}?limit=10

Returns all previous searches for the keyword, sorted latest-first.

Example:

{
  "keyword": "AI",
  "history": [
    { "_id": "...", "created_at": "...", "results": [...] }
  ]
}

3ï¸âƒ£ Get Overall Combined Summary
GET /trend_summary/{keyword}

This endpoint:

Tries to retrieve the latest stored results

If not found â†’ automatically fetches fresh data

Generates a full overall summary combining all sources

Returns high-level insights for that keyword

Sample Output
{
  "keyword": "AI",
  "overall_summary": "AI is trending due to major LLM updates, industry adoption, and discussions on ethics..."
}

ğŸ”„ **Workflow**
User enters a keyword â†’ Backend does:

ğŸ” Fetch Reddit comments

ğŸ— Fetch News articles

ğŸ¦ Fetch Tweets

ğŸ§  Run sentiment analysis on every item

âœï¸ Generate short summary per item

ğŸ’¾ Save results to MongoDB

ğŸ“¤ Return data to frontend

When summary is needed â†’

/trend_summary/{keyword} loads the latest results

If no previous results â†’ fetches fresh

Generates a single Overall Summary using:

generate_overall_summary(results, keyword)

â–¶ï¸ How to Run the Project

1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/trend-analyzer.git
cd trend-analyzer/backend

2ï¸âƒ£ Create Virtual Environment
python -m venv env
source env/bin/activate  # Windows: env\\Scripts\\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run the FastAPI Backend
uvicorn main:app --reload

5ï¸âƒ£ Start Frontend (if using)
cd frontend
npm install
npm start

âœ¨ **Future Enhancements**

Add livestreaming trending graphs

Add Twitter API full integration

Add YouTube trending & comments

Add auto-scheduling using n8n / Make

Add RAG-based context summaries

ğŸ‘¤ **Author**

Saloni Jain
AI/ML Developer | Generative AI | Automation

â­ **Support**

If you like this project, consider giving it a star â­ on GitHub!
